{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting synthetic experiments\n",
      "Running F1 trial 1/10\n",
      "Starting training...\n",
      "Early stopping enabled\n",
      "Epoch 1/100, Training Loss: 1.0117Validation Loss: 379.2906\n",
      "Epoch 2/100, Training Loss: 1.0046Validation Loss: 379.2833\n",
      "Epoch 3/100, Training Loss: 1.0040Validation Loss: 379.2813\n",
      "Epoch 4/100, Training Loss: 1.0023Validation Loss: 379.2739\n",
      "Epoch 5/100, Training Loss: 1.0017Validation Loss: 379.2816\n",
      "Epoch 6/100, Training Loss: 1.0014Validation Loss: 379.2782\n",
      "Epoch 7/100, Training Loss: 1.0002Validation Loss: 379.2734\n",
      "Epoch 8/100, Training Loss: 1.0015Validation Loss: 379.2850\n",
      "Epoch 9/100, Training Loss: 1.0007Validation Loss: 379.2786\n",
      "Epoch 10/100, Training Loss: 1.0010Validation Loss: 379.2766\n",
      "Epoch 11/100, Training Loss: 1.0048Validation Loss: 379.2904\n",
      "Early stopping at epoch 12\n",
      "Starting training...\n",
      "Early stopping enabled\n",
      "Epoch 1/100, Training Loss: 1.0108Validation Loss: 379.2976\n",
      "Epoch 2/100, Training Loss: 1.0055Validation Loss: 379.2971\n",
      "Epoch 3/100, Training Loss: 1.0029Validation Loss: 379.2840\n",
      "Epoch 4/100, Training Loss: 1.0030Validation Loss: 379.2868\n",
      "Epoch 5/100, Training Loss: 1.0027Validation Loss: 379.2881\n",
      "Epoch 6/100, Training Loss: 1.0011Validation Loss: 379.2752\n",
      "Epoch 7/100, Training Loss: 1.0024Validation Loss: 379.2997\n",
      "Epoch 8/100, Training Loss: 1.0031Validation Loss: 379.2928\n",
      "Epoch 9/100, Training Loss: 1.0029Validation Loss: 379.2898\n",
      "Epoch 10/100, Training Loss: 1.0024Validation Loss: 379.2810\n",
      "Early stopping at epoch 11\n",
      "Starting training...\n",
      "Early stopping enabled\n",
      "Epoch 1/100, Training Loss: 1.0215Validation Loss: 379.3130\n",
      "Epoch 2/100, Training Loss: 1.0030Validation Loss: 379.2974\n",
      "Epoch 3/100, Training Loss: 1.0028Validation Loss: 379.2921\n",
      "Epoch 4/100, Training Loss: 1.0020Validation Loss: 379.2846\n",
      "Epoch 5/100, Training Loss: 1.0019Validation Loss: 379.2961\n",
      "Epoch 6/100, Training Loss: 1.0014Validation Loss: 379.2916\n",
      "Epoch 7/100, Training Loss: 1.0018Validation Loss: 379.2950\n",
      "Epoch 8/100, Training Loss: 1.0019Validation Loss: 379.2914\n",
      "Early stopping at epoch 9\n",
      "Starting training...\n",
      "Early stopping enabled\n",
      "Epoch 1/100, Training Loss: 1.0285Validation Loss: 379.2950\n",
      "Epoch 2/100, Training Loss: 1.0043Validation Loss: 379.2992\n",
      "Epoch 3/100, Training Loss: 1.0035Validation Loss: 379.2832\n",
      "Epoch 4/100, Training Loss: 1.0033Validation Loss: 379.2846\n",
      "Epoch 5/100, Training Loss: 1.0036Validation Loss: 379.2917\n",
      "Epoch 6/100, Training Loss: 1.0038Validation Loss: 379.2923\n",
      "Epoch 7/100, Training Loss: 1.0031Validation Loss: 379.2921\n",
      "Early stopping at epoch 8\n",
      "Starting training...\n",
      "Early stopping enabled\n",
      "Epoch 1/100, Training Loss: 1.0685Validation Loss: 379.3004\n",
      "Epoch 2/100, Training Loss: 1.0166Validation Loss: 379.2932\n",
      "Epoch 3/100, Training Loss: 1.0153Validation Loss: 379.3012\n",
      "Epoch 4/100, Training Loss: 1.0156Validation Loss: 379.2904\n",
      "Epoch 5/100, Training Loss: 1.0156Validation Loss: 379.2921\n",
      "Epoch 6/100, Training Loss: 1.0150Validation Loss: 379.2877\n",
      "Epoch 7/100, Training Loss: 1.0147Validation Loss: 379.2903\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m trial \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msynthetic\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrials\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_synthetic_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     func_results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\valer\\.vscode\\neural-interaction-detection\\src\\experiments\\run_experiments.py:125\u001b[0m, in \u001b[0;36mrun_synthetic_trial\u001b[1;34m(func, config)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l1 \u001b[38;5;129;01min\u001b[39;00m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msynthetic\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml1_range\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    119\u001b[0m     model \u001b[38;5;241m=\u001b[39m model_class(\n\u001b[0;32m    120\u001b[0m         num_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m    121\u001b[0m         hidden_units\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m140\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m60\u001b[39m, \u001b[38;5;241m20\u001b[39m],\n\u001b[0;32m    122\u001b[0m         main_effect_net_units\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m model_class \u001b[38;5;241m==\u001b[39m MLP_M \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m     )\u001b[38;5;241m.\u001b[39mto(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m--> 125\u001b[0m     _, val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_const\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ml1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m val_loss \u001b[38;5;241m<\u001b[39m best_val_loss:\n\u001b[0;32m    132\u001b[0m         best_l1, best_val_loss \u001b[38;5;241m=\u001b[39m l1, val_loss\n",
      "File \u001b[1;32mc:\\Users\\valer\\.vscode\\neural-interaction-detection\\src\\neural_detection\\multilayer_perceptron.py:298\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(net, data_loaders, criterion, nepochs, verbose, early_stopping, patience, l1_const, l2_const, learning_rate, opt_func, device)\u001b[0m\n\u001b[0;32m    295\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m    296\u001b[0m run_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 298\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_loaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\valer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    714\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\valer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\valer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\valer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:398\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\valer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:212\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    208\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m--> 212\u001b[0m         \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[0;32m    214\u001b[0m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\valer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:155\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 155\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\Users\\valer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:272\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    270\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    271\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from src.experiments.run_experiments import setup_environment, CONFIG, run_realworld_experiment, run_synthetic_trial, plot_results\n",
    "\n",
    "setup_environment(CONFIG)\n",
    "results = {\"synthetic\": {}, \"real_world\": {}}\n",
    "    \n",
    "print(\"Starting synthetic experiments\")\n",
    "for func in CONFIG[\"synthetic\"][\"functions\"]:\n",
    "    func_results = []\n",
    "    for trial in range(CONFIG[\"synthetic\"][\"trials\"]):\n",
    "        try:\n",
    "            print(f\"Running {func.__name__} trial {trial+1}/{CONFIG['synthetic']['trials']}\")\n",
    "            result = run_synthetic_trial(func, CONFIG)\n",
    "            func_results.append(result)\n",
    "        except Exception as e:\n",
    "            print(f\"Trial failed for {func.__name__}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "        results[\"synthetic\"][func.__name__] = func_results\n",
    "    \n",
    "print(\"\\nStarting real-world experiments\")\n",
    "for dataset in CONFIG[\"real_world\"][\"datasets\"]:\n",
    "    print(f\"Processing {dataset}\")\n",
    "    results[\"real_world\"][dataset] = run_realworld_experiment(dataset, CONFIG)\n",
    "\n",
    "torch.save(results, os.path.join(CONFIG[\"paths\"][\"results\"], \"full_results.pt\"))\n",
    "plot_results(results, CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment from github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from neural_interaction_detection import get_interactions\n",
    "from multilayer_perceptron import MLP, train, get_weights\n",
    "from utils import preprocess_data, get_pairwise_auc, get_anyorder_R_precision, set_seed, print_rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate synthetic data with ground truth interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_main_effect_nets = True # toggle this to use \"main effect\" nets\n",
    "num_samples = 30000\n",
    "num_features = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synth_func(X):\n",
    "    X1, X2, X3, X4, X5, X6, X7, X8, X9, X10 = X.transpose()\n",
    "\n",
    "    interaction1 = np.exp(np.abs(X1-X2))                        \n",
    "    interaction2 = np.abs(X2*X3)  \n",
    "    interaction3 = -1*(X3**2)**np.abs(X4) \n",
    "    interaction4 = (X1*X4)**2\n",
    "    interaction5 = np.log(X4**2 + X5**2 + X7**2 + X8**2)\n",
    "    main_effects = X9 + 1/(1 + X10**2)\n",
    "\n",
    "    Y =              interaction1 + interaction2 + interaction3 + interaction4 + interaction5 + main_effects\n",
    "    ground_truth = [     {1,2},        {2,3},         {3,4},         {1,4},        {4,5,7,8}     ]\n",
    "    \n",
    "    return Y, ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "X = np.random.uniform(low=-1, high=1, size=(num_samples,num_features))\n",
    "Y, ground_truth = synth_func(X)\n",
    "data_loaders = preprocess_data(X, Y, valid_size=10000, test_size=10000, std_scale=True, get_torch_loaders=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a multilayer perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "model = MLP(num_features, [140, 100, 60, 20], use_main_effect_nets=use_main_effect_nets).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to train\n",
      "early stopping enabled\n",
      "[epoch 1, total 100] train loss: 0.1921, val loss: 0.0548\n",
      "[epoch 3, total 100] train loss: 0.0290, val loss: 0.0283\n",
      "[epoch 5, total 100] train loss: 0.0239, val loss: 0.0557\n",
      "[epoch 7, total 100] train loss: 0.0151, val loss: 0.0168\n",
      "[epoch 9, total 100] train loss: 0.0143, val loss: 0.0184\n",
      "[epoch 11, total 100] train loss: 0.0116, val loss: 0.0083\n",
      "[epoch 13, total 100] train loss: 0.0123, val loss: 0.0117\n",
      "[epoch 15, total 100] train loss: 0.0104, val loss: 0.0094\n",
      "[epoch 17, total 100] train loss: 0.0077, val loss: 0.0137\n",
      "[epoch 19, total 100] train loss: 0.0083, val loss: 0.0139\n",
      "[epoch 21, total 100] train loss: 0.0070, val loss: 0.0054\n",
      "[epoch 23, total 100] train loss: 0.0091, val loss: 0.0063\n",
      "[epoch 25, total 100] train loss: 0.0111, val loss: 0.0099\n",
      "[epoch 27, total 100] train loss: 0.0064, val loss: 0.0068\n",
      "early stopping!\n",
      "Finished Training. Test loss:  0.005764756351709366\n"
     ]
    }
   ],
   "source": [
    "model, mlp_loss = train(model, data_loaders, device=device, learning_rate=1e-2, l1_const = 5e-5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the MLP's learned weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = get_weights(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect interactions from the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise interactions              Arbitrary-order interactions\n",
      "(1, 2)        7.8430                      (1, 2)        6.8951        \n",
      "(4, 8)        3.1959                      (2, 3)        2.0953        \n",
      "(5, 8)        3.0521                      (7, 8)        1.7971        \n",
      "(7, 8)        3.0290                      (4, 5, 8)     1.6026        \n",
      "(4, 5)        2.8506                      (1, 4)        1.5912        \n",
      "(2, 3)        2.6294                      (5, 7)        1.5261        \n",
      "(1, 4)        2.5037                      (3, 4)        1.3500        \n",
      "(5, 7)        2.4460                      (4, 7)        1.0580        \n",
      "(4, 7)        2.2369                      (4, 7, 8)     0.7727        \n",
      "(3, 4)        1.8870                      (4, 5, 7, 8)  0.5467        \n"
     ]
    }
   ],
   "source": [
    "anyorder_interactions = get_interactions(model_weights, one_indexed=True)\n",
    "pairwise_interactions = get_interactions(model_weights, pairwise=True, one_indexed=True)\n",
    "\n",
    "        \n",
    "print_rankings(pairwise_interactions, anyorder_interactions, top_k=10, spacing=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise AUC 1.0 , Any-order R-Precision 1.0\n"
     ]
    }
   ],
   "source": [
    "auc = get_pairwise_auc(pairwise_interactions, ground_truth)\n",
    "r_prec = get_anyorder_R_precision(anyorder_interactions, ground_truth)\n",
    "\n",
    "print(\"Pairwise AUC\", auc, \", Any-order R-Precision\", r_prec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
