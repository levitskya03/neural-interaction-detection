{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting real-world experiments\n",
      "Processing cal_housing\n",
      "Succesfully Loaded cal_housing!\n",
      "[[   8.3252       41.            6.98412698 ...    2.55555556\n",
      "    37.88       -122.23      ]\n",
      " [   8.3014       21.            6.23813708 ...    2.10984183\n",
      "    37.86       -122.22      ]\n",
      " [   7.2574       52.            8.28813559 ...    2.80225989\n",
      "    37.85       -122.24      ]\n",
      " ...\n",
      " [   1.7          17.            5.20554273 ...    2.3256351\n",
      "    39.43       -121.22      ]\n",
      " [   1.8672       18.            5.32951289 ...    2.12320917\n",
      "    39.43       -121.32      ]\n",
      " [   2.3886       16.            5.25471698 ...    2.61698113\n",
      "    39.37       -121.24      ]] [4.526 3.585 3.521 ... 0.923 0.847 0.894] data\n",
      "{'train': array([[ 2.34476576,  0.98214266,  0.62855945, ..., -0.04959654,\n",
      "         1.05254828, -1.32783522],\n",
      "       [ 2.33223796, -0.60701891,  0.32704136, ..., -0.09251223,\n",
      "         1.04318455, -1.32284391],\n",
      "       [ 1.7826994 ,  1.85618152,  1.15562047, ..., -0.02584253,\n",
      "         1.03850269, -1.33282653],\n",
      "       ...,\n",
      "       [-1.14259331, -0.92485123, -0.09031802, ..., -0.0717345 ,\n",
      "         1.77823747, -0.8237132 ],\n",
      "       [-1.05458292, -0.84539315, -0.04021111, ..., -0.09122515,\n",
      "         1.77823747, -0.87362627],\n",
      "       [-0.78012947, -1.00430931, -0.07044252, ..., -0.04368215,\n",
      "         1.75014627, -0.83369581]], shape=(20640, 8)), 'scaler': StandardScaler()} {'train': array([[ 2.12963148],\n",
      "       [ 1.31415614],\n",
      "       [ 1.25869341],\n",
      "       ...,\n",
      "       [-0.99274649],\n",
      "       [-1.05860847],\n",
      "       [-1.01787803]], shape=(20640, 1)), 'scaler': StandardScaler()} after processing\n",
      "{'train': <torch.utils.data.dataloader.DataLoader object at 0x000002B935F7B3E0>} loaders\n",
      "Starting training...\n",
      "Epoch 1/100, Training Loss: 0.4607\n",
      "Epoch 2/100, Training Loss: 0.3091\n",
      "Epoch 3/100, Training Loss: 0.2863\n",
      "Epoch 4/100, Training Loss: 0.2708\n",
      "Epoch 5/100, Training Loss: 0.2634\n",
      "Epoch 6/100, Training Loss: 0.2641\n",
      "Epoch 7/100, Training Loss: 0.2571\n",
      "Epoch 8/100, Training Loss: 0.2595\n",
      "Epoch 9/100, Training Loss: 0.2567\n",
      "Epoch 10/100, Training Loss: 0.2498\n",
      "Epoch 11/100, Training Loss: 0.2492\n",
      "Epoch 12/100, Training Loss: 0.2425\n",
      "Epoch 13/100, Training Loss: 0.2381\n",
      "Epoch 14/100, Training Loss: 0.2399\n",
      "Epoch 15/100, Training Loss: 0.2374\n",
      "Epoch 16/100, Training Loss: 0.2320\n",
      "Epoch 17/100, Training Loss: 0.2353\n",
      "Epoch 18/100, Training Loss: 0.2520\n",
      "Epoch 19/100, Training Loss: 0.4703\n",
      "Epoch 20/100, Training Loss: 0.3250\n",
      "Epoch 21/100, Training Loss: 0.2769\n",
      "Epoch 22/100, Training Loss: 0.2738\n",
      "Epoch 23/100, Training Loss: 0.4847\n",
      "Epoch 24/100, Training Loss: 1.2223\n",
      "Epoch 25/100, Training Loss: 0.3567\n",
      "Epoch 26/100, Training Loss: 0.4208\n",
      "Epoch 27/100, Training Loss: 0.3113\n",
      "Epoch 28/100, Training Loss: 0.2909\n",
      "Epoch 29/100, Training Loss: 0.2837\n",
      "Epoch 30/100, Training Loss: 0.2770\n",
      "Epoch 31/100, Training Loss: 0.2746\n",
      "Epoch 32/100, Training Loss: 0.2667\n",
      "Epoch 33/100, Training Loss: 0.2653\n",
      "Epoch 34/100, Training Loss: 0.2605\n",
      "Epoch 35/100, Training Loss: 0.2619\n",
      "Epoch 36/100, Training Loss: 0.2555\n",
      "Epoch 37/100, Training Loss: 0.2549\n",
      "Epoch 38/100, Training Loss: 0.2511\n",
      "Epoch 39/100, Training Loss: 0.2511\n",
      "Epoch 40/100, Training Loss: 0.2494\n",
      "Epoch 41/100, Training Loss: 0.2475\n",
      "Epoch 42/100, Training Loss: 0.2483\n",
      "Epoch 43/100, Training Loss: 0.2465\n",
      "Epoch 44/100, Training Loss: 0.2444\n",
      "Epoch 45/100, Training Loss: 0.2506\n",
      "Epoch 46/100, Training Loss: 0.2464\n",
      "Epoch 47/100, Training Loss: 0.2441\n",
      "Epoch 48/100, Training Loss: 0.2387\n",
      "Epoch 49/100, Training Loss: 0.2352\n",
      "Epoch 50/100, Training Loss: 0.2364\n",
      "Epoch 51/100, Training Loss: 0.2328\n",
      "Epoch 52/100, Training Loss: 0.2376\n",
      "Epoch 53/100, Training Loss: 0.2329\n",
      "Epoch 54/100, Training Loss: 0.2303\n",
      "Epoch 55/100, Training Loss: 0.2323\n",
      "Epoch 56/100, Training Loss: 0.2357\n",
      "Epoch 57/100, Training Loss: 0.2319\n",
      "Epoch 58/100, Training Loss: 0.2287\n",
      "Epoch 59/100, Training Loss: 0.2243\n",
      "Epoch 60/100, Training Loss: 0.2244\n",
      "Epoch 61/100, Training Loss: 0.2247\n",
      "Epoch 62/100, Training Loss: 0.2212\n",
      "Epoch 63/100, Training Loss: 0.2216\n",
      "Epoch 64/100, Training Loss: 0.2231\n",
      "Epoch 65/100, Training Loss: 0.2243\n",
      "Epoch 66/100, Training Loss: 0.2216\n",
      "Epoch 67/100, Training Loss: 0.2194\n",
      "Epoch 68/100, Training Loss: 0.2167\n",
      "Epoch 69/100, Training Loss: 0.2193\n",
      "Epoch 70/100, Training Loss: 0.2191\n",
      "Epoch 71/100, Training Loss: 0.2185\n",
      "Epoch 72/100, Training Loss: 0.2213\n",
      "Epoch 73/100, Training Loss: 0.2198\n",
      "Epoch 74/100, Training Loss: 0.6646\n",
      "Epoch 75/100, Training Loss: 0.2692\n",
      "Epoch 76/100, Training Loss: 0.2540\n",
      "Epoch 77/100, Training Loss: 0.2458\n",
      "Epoch 78/100, Training Loss: 0.2412\n",
      "Epoch 79/100, Training Loss: 0.2349\n",
      "Epoch 80/100, Training Loss: 0.2338\n",
      "Epoch 81/100, Training Loss: 0.2432\n",
      "Epoch 82/100, Training Loss: 0.2860\n",
      "Epoch 83/100, Training Loss: 0.2468\n",
      "Epoch 84/100, Training Loss: 0.2591\n",
      "Epoch 85/100, Training Loss: 0.2440\n",
      "Epoch 86/100, Training Loss: 0.2409\n",
      "Epoch 87/100, Training Loss: 0.2366\n",
      "Epoch 88/100, Training Loss: 0.2323\n",
      "Epoch 89/100, Training Loss: 0.2349\n",
      "Epoch 90/100, Training Loss: 0.2329\n",
      "Epoch 91/100, Training Loss: 0.2315\n",
      "Epoch 92/100, Training Loss: 0.2319\n",
      "Epoch 93/100, Training Loss: 0.2300\n",
      "Epoch 94/100, Training Loss: 0.2415\n",
      "Epoch 95/100, Training Loss: 0.2329\n",
      "Epoch 96/100, Training Loss: 0.2299\n",
      "Epoch 97/100, Training Loss: 0.2270\n",
      "Epoch 98/100, Training Loss: 0.2279\n",
      "Epoch 99/100, Training Loss: 0.2303\n",
      "Epoch 100/100, Training Loss: 0.2257\n",
      "Starting training...\n",
      "Epoch 1/100, Training Loss: 1.4764\n",
      "Epoch 2/100, Training Loss: 0.6485\n",
      "Epoch 3/100, Training Loss: 0.4916\n",
      "Epoch 4/100, Training Loss: 0.4209\n",
      "Epoch 5/100, Training Loss: 0.3758\n",
      "Epoch 6/100, Training Loss: 0.3612\n",
      "Epoch 7/100, Training Loss: 0.3308\n",
      "Epoch 8/100, Training Loss: 0.3198\n",
      "Epoch 9/100, Training Loss: 0.3077\n",
      "Epoch 10/100, Training Loss: 0.3007\n",
      "Epoch 11/100, Training Loss: 0.3041\n",
      "Epoch 12/100, Training Loss: 0.2929\n",
      "Epoch 13/100, Training Loss: 0.2887\n",
      "Epoch 14/100, Training Loss: 0.2844\n",
      "Epoch 15/100, Training Loss: 0.2804\n",
      "Epoch 16/100, Training Loss: 0.2833\n",
      "Epoch 17/100, Training Loss: 0.2812\n",
      "Epoch 18/100, Training Loss: 0.2821\n",
      "Epoch 19/100, Training Loss: 0.2850\n",
      "Epoch 20/100, Training Loss: 0.3496\n",
      "Epoch 21/100, Training Loss: 0.3050\n",
      "Epoch 22/100, Training Loss: 0.3049\n",
      "Epoch 23/100, Training Loss: 0.2902\n",
      "Epoch 24/100, Training Loss: 0.2925\n",
      "Epoch 25/100, Training Loss: 0.2890\n",
      "Epoch 26/100, Training Loss: 0.2841\n",
      "Epoch 27/100, Training Loss: 0.2780\n",
      "Epoch 28/100, Training Loss: 0.2791\n",
      "Epoch 29/100, Training Loss: 0.2710\n",
      "Epoch 30/100, Training Loss: 0.2758\n",
      "Epoch 31/100, Training Loss: 0.2752\n",
      "Epoch 32/100, Training Loss: 0.2725\n",
      "Epoch 33/100, Training Loss: 0.2682\n",
      "Epoch 34/100, Training Loss: 0.2662\n",
      "Epoch 35/100, Training Loss: 0.2676\n",
      "Epoch 36/100, Training Loss: 0.2655\n",
      "Epoch 37/100, Training Loss: 0.2643\n",
      "Epoch 38/100, Training Loss: 0.2720\n",
      "Epoch 39/100, Training Loss: 0.2688\n",
      "Epoch 40/100, Training Loss: 0.2620\n",
      "Epoch 41/100, Training Loss: 0.2630\n",
      "Epoch 42/100, Training Loss: 0.2628\n",
      "Epoch 43/100, Training Loss: 0.2641\n",
      "Epoch 44/100, Training Loss: 0.2628\n",
      "Epoch 45/100, Training Loss: 0.2655\n",
      "Epoch 46/100, Training Loss: 0.2637\n",
      "Epoch 47/100, Training Loss: 0.2664\n",
      "Epoch 48/100, Training Loss: 0.2637\n",
      "Epoch 49/100, Training Loss: 0.2590\n",
      "Epoch 50/100, Training Loss: 0.2635\n",
      "Epoch 51/100, Training Loss: 0.2592\n",
      "Epoch 52/100, Training Loss: 0.2612\n",
      "Epoch 53/100, Training Loss: 0.2597\n",
      "Epoch 54/100, Training Loss: 0.2623\n",
      "Epoch 55/100, Training Loss: 0.2565\n",
      "Epoch 56/100, Training Loss: 0.2623\n",
      "Epoch 57/100, Training Loss: 0.2614\n",
      "Epoch 58/100, Training Loss: 0.2604\n",
      "Epoch 59/100, Training Loss: 0.2615\n",
      "Epoch 60/100, Training Loss: 0.2556\n",
      "Epoch 61/100, Training Loss: 0.2577\n",
      "Epoch 62/100, Training Loss: 0.2592\n",
      "Epoch 63/100, Training Loss: 0.2636\n",
      "Epoch 64/100, Training Loss: 0.2565\n",
      "Epoch 65/100, Training Loss: 0.2604\n",
      "Epoch 66/100, Training Loss: 0.2582\n",
      "Epoch 67/100, Training Loss: 0.2566\n",
      "Epoch 68/100, Training Loss: 0.2645\n",
      "Epoch 69/100, Training Loss: 0.2594\n",
      "Epoch 70/100, Training Loss: 0.2582\n",
      "Epoch 71/100, Training Loss: 0.2622\n",
      "Epoch 72/100, Training Loss: 0.2534\n",
      "Epoch 73/100, Training Loss: 0.2553\n",
      "Epoch 74/100, Training Loss: 0.2568\n",
      "Epoch 75/100, Training Loss: 0.2551\n",
      "Epoch 76/100, Training Loss: 0.2604\n",
      "Epoch 77/100, Training Loss: 0.2507\n",
      "Epoch 78/100, Training Loss: 0.2533\n",
      "Epoch 79/100, Training Loss: 0.2531\n",
      "Epoch 80/100, Training Loss: 0.2538\n",
      "Epoch 81/100, Training Loss: 0.2497\n",
      "Epoch 82/100, Training Loss: 0.2532\n",
      "Epoch 83/100, Training Loss: 0.2594\n",
      "Epoch 84/100, Training Loss: 0.2541\n",
      "Epoch 85/100, Training Loss: 0.2572\n",
      "Epoch 86/100, Training Loss: 0.2546\n",
      "Epoch 87/100, Training Loss: 0.2511\n",
      "Epoch 88/100, Training Loss: 0.2591\n",
      "Epoch 89/100, Training Loss: 0.2567\n",
      "Epoch 90/100, Training Loss: 0.2520\n",
      "Epoch 91/100, Training Loss: 0.2514\n",
      "Epoch 92/100, Training Loss: 0.2575\n",
      "Epoch 93/100, Training Loss: 0.2669\n",
      "Epoch 94/100, Training Loss: 0.2695\n",
      "Epoch 95/100, Training Loss: 0.2626\n",
      "Epoch 96/100, Training Loss: 0.2607\n",
      "Epoch 97/100, Training Loss: 0.2835\n",
      "Epoch 98/100, Training Loss: 0.2983\n",
      "Epoch 99/100, Training Loss: 0.2801\n",
      "Epoch 100/100, Training Loss: 0.2716\n",
      "Error in training real datasets list index out of range\n",
      "Processing bike_sharing\n",
      "Succesfully Loaded bike_sharing!\n",
      "[[ 1.        0.        1.       ...  0.363625  0.805833  0.160446]\n",
      " [ 1.        0.        1.       ...  0.353739  0.696087  0.248539]\n",
      " [ 1.        0.        1.       ...  0.189405  0.437273  0.248309]\n",
      " ...\n",
      " [ 1.        1.       12.       ...  0.2424    0.752917  0.124383]\n",
      " [ 1.        1.       12.       ...  0.2317    0.483333  0.350754]\n",
      " [ 1.        1.       12.       ...  0.223487  0.5775    0.154846]] [ 985  801 1349 1562 1600 1606 1510  959  822 1321 1263 1162 1406 1421\n",
      " 1248 1204 1000  683 1650 1927 1543  981  986 1416 1985  506  431 1167\n",
      " 1098 1096 1501 1360 1526 1550 1708 1005 1623 1712 1530 1605 1538 1746\n",
      " 1472 1589 1913 1815 2115 2475 2927 1635 1812 1107 1450 1917 1807 1461\n",
      " 1969 2402 1446 1851 2134 1685 1944 2077  605 1872 2133 1891  623 1977\n",
      " 2132 2417 2046 2056 2192 2744 3239 3117 2471 2077 2703 2121 1865 2210\n",
      " 2496 1693 2028 2425 1536 1685 2227 2252 3249 3115 1795 2808 3141 1471\n",
      " 2455 2895 3348 2034 2162 3267 3126  795 3744 3429 3204 3944 4189 1683\n",
      " 4036 4191 4073 4400 3872 4058 4595 5312 3351 4401 4451 2633 4433 4608\n",
      " 4714 4333 4362 4803 4182 4864 4105 3409 4553 3958 4123 3855 4575 4917\n",
      " 5805 4660 4274 4492 4978 4677 4679 4758 4788 4098 3982 3974 4968 5312\n",
      " 5342 4906 4548 4833 4401 3915 4586 4966 4460 5020 4891 5180 3767 4844\n",
      " 5119 4744 4010 4835 4507 4790 4991 5202 5305 4708 4648 5225 5515 5362\n",
      " 5119 4649 6043 4665 4629 4592 4040 5336 4881 4086 4258 4342 5084 5538\n",
      " 5923 5302 4458 4541 4332 3784 3387 3285 3606 3840 4590 4656 4390 3846\n",
      " 4475 4302 4266 4845 3574 4576 4866 4294 3785 4326 4602 4780 4792 4905\n",
      " 4150 3820 4338 4725 4694 3805 4153 5191 3873 4758 5895 5130 3542 4661\n",
      " 1115 4334 4634 5204 5058 5115 4727 4484 4940 3351 2710 1996 1842 3544\n",
      " 5345 5046 4713 4763 4785 3659 4760 4511 4274 4539 3641 4352 4795 2395\n",
      " 5423 5010 4630 4120 3907 4839 5202 2429 2918 3570 4456 4826 4765 4985\n",
      " 5409 5511 5117 4563 2416 2913 3644 5217 5041 4570 4748 2424 4195 4304\n",
      " 4308 4381 4187 4687 3894 2659 3747  627 3331 3669 4068 4186 3974 4046\n",
      " 3926 3649 4035 4205 4109 2933 3368 4067 3717 4486 4195 1817 3053 3392\n",
      " 3663 3520 2765 1607 2566 1495 2792 3068 3071 3867 2914 3613 3727 3940\n",
      " 3614 3485 3811 2594  705 3322 3620 3190 2743 3310 3523 3740 3709 3577\n",
      " 2739 2431 3403 3750 2660 3068 2209 1011  754 1317 1162 2302 2423 2999\n",
      " 2485 2294 1951 2236 2368 3272 4098 4521 3425 2376 3598 2177 4097 3214\n",
      " 2493 2311 2298 2935 3376 3292 3163 1301 1977 2432 4339 4270 4075 3456\n",
      " 4023 3243 3624 4509 4579 3761 4151 2832 2947 3784 4375 2802 3830 3831\n",
      " 2169 1529 3422 3922 4169 3005 4154 4318 2689 3129 3777 4773 5062 3487\n",
      " 2732 3389 4322 4363 1834 4990 3194 4066 3423 3333 3956 4916 5382 4569\n",
      " 4118 4911 5298 5847 6312 6192 4378 7836 5892 6153 6093 6230 6871 8362\n",
      " 3372 4996 5558 5102 5698 6133 5459 6235 6041 5936 6772 6436 6457 6460\n",
      " 6857 5169 5585 5918 4862 5409 6398 7460 7132 6370 6691 4367 6565 7290\n",
      " 6624 1027 3214 5633 6196 5026 6233 4220 6304 5572 5740 6169 6421 6296\n",
      " 6883 6359 6273 5728 4717 6572 7030 7429 6118 2843 5115 7424 7384 7639\n",
      " 8294 7129 4359 6073 5260 6770 6734 6536 6591 6043 5743 6855 7338 4127\n",
      " 8120 7641 6998 7001 7055 7494 7736 7498 6598 6664 4972 7421 7363 7665\n",
      " 7702 6978 5099 6825 6211 5905 5823 7458 6891 6779 7442 7335 6879 5463\n",
      " 5687 5531 6227 6660 7403 6241 6207 4840 4672 6569 6290 7264 7446 7499\n",
      " 6969 6031 6830 6786 5713 6591 5870 4459 7410 6966 7592 8173 6861 6904\n",
      " 6685 6597 7105 7216 7580 7261 7175 6824 5464 7013 7273 7534 7286 5786\n",
      " 6299 6544 6883 6784 7347 7605 7148 7865 4549 6530 7006 7375 7765 7582\n",
      " 6053 5255 6917 7040 7697 7713 7350 6140 5810 6034 6864 7112 6203 7504\n",
      " 5976 8227 7525 7767 7870 7804 8009 8714 7333 6869 4073 7591 7720 8167\n",
      " 8395 7907 7436 7538 7733 7393 7415 8555 6889 6778 4639 7572 7328 8156\n",
      " 7965 3510 5478 6392 7691 7570 7282 7109 6639 5875 7534 7461 7509 5424\n",
      " 8090 6824 7058 7466 7693 7359 7444 7852 4459   22 1096 5566 5986 5847\n",
      " 5138 5107 5259 5686 5035 5315 5992 6536 6852 6269 4094 5495 5445 5698\n",
      " 5629 4669 5499 5634 5146 2425 3910 2277 2424 5087 3959 5260 5323 5668\n",
      " 5191 4649 6234 6606 5729 5375 5008 5582 3228 5170 5501 5319 5532 5611\n",
      " 5047 3786 4585 5557 5267 4128 3623 1749 1787  920 1013  441 2114 3095\n",
      " 1341 1796 2729] data\n",
      "{'train': array([[-1.34821315, -1.00136893, -1.60016072, ..., -0.67994602,\n",
      "         1.25017133, -0.38789169],\n",
      "       [-1.34821315, -1.00136893, -1.60016072, ..., -0.74065231,\n",
      "         0.47911298,  0.74960172],\n",
      "       [-1.34821315, -1.00136893, -1.60016072, ..., -1.749767  ,\n",
      "        -1.33927398,  0.74663186],\n",
      "       ...,\n",
      "       [-1.34821315,  0.99863295,  1.58866019, ..., -1.42434419,\n",
      "         0.87839173, -0.85355213],\n",
      "       [-1.34821315,  0.99863295,  1.58866019, ..., -1.49004895,\n",
      "        -1.01566357,  2.06944426],\n",
      "       [-1.34821315,  0.99863295,  1.58866019, ..., -1.54048197,\n",
      "        -0.35406086, -0.46020122]], shape=(731, 11)), 'scaler': StandardScaler()} {'train': array([[-1.81795256e+00],\n",
      "       [-1.91299949e+00],\n",
      "       [-1.62992496e+00],\n",
      "       [-1.51989782e+00],\n",
      "       [-1.50026856e+00],\n",
      "       [-1.49716920e+00],\n",
      "       [-1.54675890e+00],\n",
      "       [-1.83138311e+00],\n",
      "       [-1.90215174e+00],\n",
      "       [-1.64438862e+00],\n",
      "       [-1.67434906e+00],\n",
      "       [-1.72652156e+00],\n",
      "       [-1.60048108e+00],\n",
      "       [-1.59273269e+00],\n",
      "       [-1.68209745e+00],\n",
      "       [-1.70482607e+00],\n",
      "       [-1.81020417e+00],\n",
      "       [-1.97395349e+00],\n",
      "       [-1.47444059e+00],\n",
      "       [-1.33135365e+00],\n",
      "       [-1.52971244e+00],\n",
      "       [-1.82001880e+00],\n",
      "       [-1.81743600e+00],\n",
      "       [-1.59531548e+00],\n",
      "       [-1.30139321e+00],\n",
      "       [-2.06538449e+00],\n",
      "       [-2.10412645e+00],\n",
      "       [-1.72393876e+00],\n",
      "       [-1.75958136e+00],\n",
      "       [-1.76061448e+00],\n",
      "       [-1.55140794e+00],\n",
      "       [-1.62424281e+00],\n",
      "       [-1.53849395e+00],\n",
      "       [-1.52609653e+00],\n",
      "       [-1.44448015e+00],\n",
      "       [-1.80762138e+00],\n",
      "       [-1.48838770e+00],\n",
      "       [-1.44241391e+00],\n",
      "       [-1.53642772e+00],\n",
      "       [-1.49768576e+00],\n",
      "       [-1.53229524e+00],\n",
      "       [-1.42485090e+00],\n",
      "       [-1.56638816e+00],\n",
      "       [-1.50595071e+00],\n",
      "       [-1.33858548e+00],\n",
      "       [-1.38920830e+00],\n",
      "       [-1.23424049e+00],\n",
      "       [-1.04827913e+00],\n",
      "       [-8.14794297e-01],\n",
      "       [-1.48218898e+00],\n",
      "       [-1.39075798e+00],\n",
      "       [-1.75493232e+00],\n",
      "       [-1.57775246e+00],\n",
      "       [-1.33651925e+00],\n",
      "       [-1.39334077e+00],\n",
      "       [-1.57207031e+00],\n",
      "       [-1.30965816e+00],\n",
      "       [-1.08598796e+00],\n",
      "       [-1.57981870e+00],\n",
      "       [-1.37061216e+00],\n",
      "       [-1.22442587e+00],\n",
      "       [-1.45636102e+00],\n",
      "       [-1.32257214e+00],\n",
      "       [-1.25386975e+00],\n",
      "       [-2.01424512e+00],\n",
      "       [-1.35976442e+00],\n",
      "       [-1.22494242e+00],\n",
      "       [-1.34994979e+00],\n",
      "       [-2.00494705e+00],\n",
      "       [-1.30552568e+00],\n",
      "       [-1.22545898e+00],\n",
      "       [-1.07823957e+00],\n",
      "       [-1.26988309e+00],\n",
      "       [-1.26471750e+00],\n",
      "       [-1.19446542e+00],\n",
      "       [-9.09324659e-01],\n",
      "       [-6.53627779e-01],\n",
      "       [-7.16648020e-01],\n",
      "       [-1.05034536e+00],\n",
      "       [-1.25386975e+00],\n",
      "       [-9.30503593e-01],\n",
      "       [-1.23114114e+00],\n",
      "       [-1.36338033e+00],\n",
      "       [-1.18516735e+00],\n",
      "       [-1.03743138e+00],\n",
      "       [-1.45222854e+00],\n",
      "       [-1.27918116e+00],\n",
      "       [-1.07410709e+00],\n",
      "       [-1.53332836e+00],\n",
      "       [-1.45636102e+00],\n",
      "       [-1.17638585e+00],\n",
      "       [-1.16347186e+00],\n",
      "       [-6.48462185e-01],\n",
      "       [-7.17681139e-01],\n",
      "       [-1.39953949e+00],\n",
      "       [-8.76264860e-01],\n",
      "       [-7.04250595e-01],\n",
      "       [-1.56690472e+00],\n",
      "       [-1.05861031e+00],\n",
      "       [-8.31324197e-01],\n",
      "       [-5.97322809e-01],\n",
      "       [-1.27608180e+00],\n",
      "       [-1.20996220e+00],\n",
      "       [-6.39164117e-01],\n",
      "       [-7.11998986e-01],\n",
      "       [-1.91609884e+00],\n",
      "       [-3.92765305e-01],\n",
      "       [-5.55481501e-01],\n",
      "       [-6.71707356e-01],\n",
      "       [-2.89453434e-01],\n",
      "       [-1.62896392e-01],\n",
      "       [-1.45739413e+00],\n",
      "       [-2.41929973e-01],\n",
      "       [-1.61863273e-01],\n",
      "       [-2.22817277e-01],\n",
      "       [-5.39023680e-02],\n",
      "       [-3.26645707e-01],\n",
      "       [-2.30565667e-01],\n",
      "       [ 4.68267061e-02],\n",
      "       [ 4.17199763e-01],\n",
      "       [-5.95773131e-01],\n",
      "       [-5.33858086e-02],\n",
      "       [-2.75578409e-02],\n",
      "       [-9.66662748e-01],\n",
      "       [-3.68559093e-02],\n",
      "       [ 5.35419778e-02],\n",
      "       [ 1.08297269e-01],\n",
      "       [-8.85118448e-02],\n",
      "       [-7.35316235e-02],\n",
      "       [ 1.54271052e-01],\n",
      "       [-1.66512307e-01],\n",
      "       [ 1.85781173e-01],\n",
      "       [-2.06287378e-01],\n",
      "       [-5.65812688e-01],\n",
      "       [ 2.51312132e-02],\n",
      "       [-2.82221603e-01],\n",
      "       [-1.96989309e-01],\n",
      "       [-3.35427216e-01],\n",
      "       [ 3.64955191e-02],\n",
      "       [ 2.13158818e-01],\n",
      "       [ 6.71863525e-01],\n",
      "       [ 8.04030642e-02],\n",
      "       [-1.18988847e-01],\n",
      "       [-6.37890738e-03],\n",
      "       [ 2.44668939e-01],\n",
      "       [ 8.91845732e-02],\n",
      "       [ 9.02176919e-02],\n",
      "       [ 1.31025881e-01],\n",
      "       [ 1.46522662e-01],\n",
      "       [-2.09903293e-01],\n",
      "       [-2.69824178e-01],\n",
      "       [-2.73956653e-01],\n",
      "       [ 2.39503345e-01],\n",
      "       [ 4.17199763e-01],\n",
      "       [ 4.32696544e-01],\n",
      "       [ 2.07476665e-01],\n",
      "       [ 2.25484165e-02],\n",
      "       [ 1.69767833e-01],\n",
      "       [-5.33858086e-02],\n",
      "       [-3.04433655e-01],\n",
      "       [ 4.21776720e-02],\n",
      "       [ 2.38470227e-01],\n",
      "       [-2.29088067e-02],\n",
      "       [ 2.66364432e-01],\n",
      "       [ 1.99728275e-01],\n",
      "       [ 3.49013929e-01],\n",
      "       [-3.80884439e-01],\n",
      "       [ 1.75449985e-01],\n",
      "       [ 3.17503808e-01],\n",
      "       [ 1.23794050e-01],\n",
      "       [-2.55360516e-01],\n",
      "       [ 1.70800951e-01],\n",
      "       [ 1.36948294e-03],\n",
      "       [ 1.47555780e-01],\n",
      "       [ 2.51384211e-01],\n",
      "       [ 3.60378234e-01],\n",
      "       [ 4.13583848e-01],\n",
      "       [ 1.05197913e-01],\n",
      "       [ 7.42043519e-02],\n",
      "       [ 3.72259100e-01],\n",
      "       [ 5.22061312e-01],\n",
      "       [ 4.43027731e-01],\n",
      "       [ 3.17503808e-01],\n",
      "       [ 7.47209113e-02],\n",
      "       [ 7.94804652e-01],\n",
      "       [ 8.29858610e-02],\n",
      "       [ 6.43897242e-02],\n",
      "       [ 4.52770281e-02],\n",
      "       [-2.39863736e-01],\n",
      "       [ 4.29597188e-01],\n",
      "       [ 1.94562682e-01],\n",
      "       [-2.16102005e-01],\n",
      "       [-1.27253796e-01],\n",
      "       [-8.38628106e-02],\n",
      "       [ 2.99424231e-01],\n",
      "       [ 5.33942177e-01],\n",
      "       [ 7.32817529e-01],\n",
      "       [ 4.12034170e-01],\n",
      "       [-2.39419254e-02],\n",
      "       [ 1.89325010e-02],\n",
      "       [-8.90284041e-02],\n",
      "       [-3.72102930e-01],\n",
      "       [-5.77176994e-01],\n",
      "       [-6.29866048e-01],\n",
      "       [-4.64050496e-01],\n",
      "       [-3.43175607e-01],\n",
      "       [ 4.42439094e-02],\n",
      "       [ 7.83368268e-02],\n",
      "       [-5.90679615e-02],\n",
      "       [-3.40076250e-01],\n",
      "       [-1.51604164e-02],\n",
      "       [-1.04525185e-01],\n",
      "       [-1.23121322e-01],\n",
      "       [ 1.75966545e-01],\n",
      "       [-4.80580395e-01],\n",
      "       [ 3.70120784e-02],\n",
      "       [ 1.86814291e-01],\n",
      "       [-1.08657660e-01],\n",
      "       [-3.71586371e-01],\n",
      "       [-9.21277602e-02],\n",
      "       [ 5.04426216e-02],\n",
      "       [ 1.42390187e-01],\n",
      "       [ 1.48588899e-01],\n",
      "       [ 2.06960106e-01],\n",
      "       [-1.83042207e-01],\n",
      "       [-3.53506794e-01],\n",
      "       [-8.59290480e-02],\n",
      "       [ 1.13979422e-01],\n",
      "       [ 9.79660822e-02],\n",
      "       [-3.61255184e-01],\n",
      "       [-1.81492529e-01],\n",
      "       [ 3.54696081e-01],\n",
      "       [-3.26129148e-01],\n",
      "       [ 1.31025881e-01],\n",
      "       [ 7.18353867e-01],\n",
      "       [ 3.23185961e-01],\n",
      "       [-4.97110294e-01],\n",
      "       [ 8.09196235e-02],\n",
      "       [-1.75079985e+00],\n",
      "       [-8.79952854e-02],\n",
      "       [ 6.69725210e-02],\n",
      "       [ 3.61411353e-01],\n",
      "       [ 2.85993687e-01],\n",
      "       [ 3.15437571e-01],\n",
      "       [ 1.15012541e-01],\n",
      "       [-1.05113822e-02],\n",
      "       [ 2.25039683e-01],\n",
      "       [-5.95773131e-01],\n",
      "       [-9.26887677e-01],\n",
      "       [-1.29571106e+00],\n",
      "       [-1.37526120e+00],\n",
      "       [-4.96077176e-01],\n",
      "       [ 4.34246222e-01],\n",
      "       [ 2.79794975e-01],\n",
      "       [ 1.07780710e-01],\n",
      "       [ 1.33608678e-01],\n",
      "       [ 1.44972984e-01],\n",
      "       [-4.36672850e-01],\n",
      "       [ 1.32059000e-01],\n",
      "       [ 3.43572036e-03],\n",
      "       [-1.18988847e-01],\n",
      "       [ 1.78993823e-02],\n",
      "       [-4.45970918e-01],\n",
      "       [-7.86972170e-02],\n",
      "       [ 1.50138577e-01],\n",
      "       [-1.08960387e+00],\n",
      "       [ 4.74537852e-01],\n",
      "       [ 2.61198838e-01],\n",
      "       [ 6.49062836e-02],\n",
      "       [-1.98538987e-01],\n",
      "       [-3.08566130e-01],\n",
      "       [ 1.72867189e-01],\n",
      "       [ 3.60378234e-01],\n",
      "       [-1.07204086e+00],\n",
      "       [-8.19443331e-01],\n",
      "       [-4.82646632e-01],\n",
      "       [-2.49750441e-02],\n",
      "       [ 1.66151917e-01],\n",
      "       [ 1.34641796e-01],\n",
      "       [ 2.48284854e-01],\n",
      "       [ 4.67306021e-01],\n",
      "       [ 5.19995075e-01],\n",
      "       [ 3.16470689e-01],\n",
      "       [ 3.02968068e-02],\n",
      "       [-1.07875613e+00],\n",
      "       [-8.22026128e-01],\n",
      "       [-4.44421240e-01],\n",
      "       [ 3.68126625e-01],\n",
      "       [ 2.77212178e-01],\n",
      "       [ 3.39127223e-02],\n",
      "       [ 1.25860287e-01],\n",
      "       [-1.07462365e+00],\n",
      "       [-1.59797036e-01],\n",
      "       [-1.03492066e-01],\n",
      "       [-1.01425829e-01],\n",
      "       [-6.37169957e-02],\n",
      "       [-1.63929511e-01],\n",
      "       [ 9.43501668e-02],\n",
      "       [-3.15281401e-01],\n",
      "       [-9.53232204e-01],\n",
      "       [-3.91215627e-01],\n",
      "       [-2.00288081e+00],\n",
      "       [-6.06104318e-01],\n",
      "       [-4.31507256e-01],\n",
      "       [-2.25400074e-01],\n",
      "       [-1.64446070e-01],\n",
      "       [-2.73956653e-01],\n",
      "       [-2.36764380e-01],\n",
      "       [-2.98751502e-01],\n",
      "       [-4.41838443e-01],\n",
      "       [-2.42446532e-01],\n",
      "       [-1.54631442e-01],\n",
      "       [-2.04221140e-01],\n",
      "       [-8.11694941e-01],\n",
      "       [-5.86991622e-01],\n",
      "       [-2.25916633e-01],\n",
      "       [-4.06712407e-01],\n",
      "       [-9.47826351e-03],\n",
      "       [-1.59797036e-01],\n",
      "       [-1.38817518e+00],\n",
      "       [-7.49707819e-01],\n",
      "       [-5.74594197e-01],\n",
      "       [-4.34606612e-01],\n",
      "       [-5.08474600e-01],\n",
      "       [-8.98476913e-01],\n",
      "       [-1.49665265e+00],\n",
      "       [-1.00127222e+00],\n",
      "       [-1.55450729e+00],\n",
      "       [-8.84529810e-01],\n",
      "       [-7.41959428e-01],\n",
      "       [-7.40409750e-01],\n",
      "       [-3.29228504e-01],\n",
      "       [-8.21509569e-01],\n",
      "       [-4.60434580e-01],\n",
      "       [-4.01546814e-01],\n",
      "       [-2.91519671e-01],\n",
      "       [-4.59918021e-01],\n",
      "       [-5.26554177e-01],\n",
      "       [-3.58155828e-01],\n",
      "       [-9.86808562e-01],\n",
      "       [-1.96258918e+00],\n",
      "       [-6.10753352e-01],\n",
      "       [-4.56818665e-01],\n",
      "       [-6.78939187e-01],\n",
      "       [-9.09841219e-01],\n",
      "       [-6.16952064e-01],\n",
      "       [-5.06924922e-01],\n",
      "       [-3.94831542e-01],\n",
      "       [-4.10844882e-01],\n",
      "       [-4.79030717e-01],\n",
      "       [-9.11907456e-01],\n",
      "       [-1.07100774e+00],\n",
      "       [-5.68912044e-01],\n",
      "       [-3.89665948e-01],\n",
      "       [-9.52715645e-01],\n",
      "       [-7.41959428e-01],\n",
      "       [-1.18568391e+00],\n",
      "       [-1.80452202e+00],\n",
      "       [-1.93727777e+00],\n",
      "       [-1.64645486e+00],\n",
      "       [-1.72652156e+00],\n",
      "       [-1.13764389e+00],\n",
      "       [-1.07514021e+00],\n",
      "       [-7.77602024e-01],\n",
      "       [-1.04311353e+00],\n",
      "       [-1.14177637e+00],\n",
      "       [-1.31895623e+00],\n",
      "       [-1.17173681e+00],\n",
      "       [-1.10355098e+00],\n",
      "       [-6.36581320e-01],\n",
      "       [-2.09903293e-01],\n",
      "       [ 8.60131390e-03],\n",
      "       [-5.57547739e-01],\n",
      "       [-1.09941850e+00],\n",
      "       [-4.68182970e-01],\n",
      "       [-1.20221381e+00],\n",
      "       [-2.10419852e-01],\n",
      "       [-6.66541763e-01],\n",
      "       [-1.03898106e+00],\n",
      "       [-1.13299486e+00],\n",
      "       [-1.13971013e+00],\n",
      "       [-8.10661822e-01],\n",
      "       [-5.82859147e-01],\n",
      "       [-6.26250133e-01],\n",
      "       [-6.92886290e-01],\n",
      "       [-1.65471981e+00],\n",
      "       [-1.30552568e+00],\n",
      "       [-1.07049118e+00],\n",
      "       [-8.54124886e-02],\n",
      "       [-1.21055084e-01],\n",
      "       [-2.21784158e-01],\n",
      "       [-5.41534399e-01],\n",
      "       [-2.48645245e-01],\n",
      "       [-6.51561541e-01],\n",
      "       [-4.54752427e-01],\n",
      "       [ 2.40260165e-03],\n",
      "       [ 3.85617565e-02],\n",
      "       [-3.83983796e-01],\n",
      "       [-1.82525647e-01],\n",
      "       [-8.63867436e-01],\n",
      "       [-8.04463110e-01],\n",
      "       [-3.72102930e-01],\n",
      "       [-6.68163519e-02],\n",
      "       [-8.79364217e-01],\n",
      "       [-3.48341200e-01],\n",
      "       [-3.47824641e-01],\n",
      "       [-1.20634629e+00],\n",
      "       [-1.53694427e+00],\n",
      "       [-5.59097417e-01],\n",
      "       [-3.00817739e-01],\n",
      "       [-1.73227579e-01],\n",
      "       [-7.74502668e-01],\n",
      "       [-1.80975969e-01],\n",
      "       [-9.62602351e-02],\n",
      "       [-9.37735424e-01],\n",
      "       [-7.10449308e-01],\n",
      "       [-3.75718846e-01],\n",
      "       [ 1.38774271e-01],\n",
      "       [ 2.88059925e-01],\n",
      "       [-5.25521059e-01],\n",
      "       [-9.15523371e-01],\n",
      "       [-5.76143875e-01],\n",
      "       [-9.41939977e-02],\n",
      "       [-7.30150641e-02],\n",
      "       [-1.37939367e+00],\n",
      "       [ 2.50867651e-01],\n",
      "       [-6.76872950e-01],\n",
      "       [-2.26433192e-01],\n",
      "       [-5.58580857e-01],\n",
      "       [-6.05071199e-01],\n",
      "       [-2.83254721e-01],\n",
      "       [ 2.12642259e-01],\n",
      "       [ 4.53358918e-01],\n",
      "       [ 3.33961629e-02],\n",
      "       [-1.99572106e-01],\n",
      "       [ 2.10059462e-01],\n",
      "       [ 4.09967932e-01],\n",
      "       [ 6.93559018e-01],\n",
      "       [ 9.33759118e-01],\n",
      "       [ 8.71771995e-01],\n",
      "       [-6.52666738e-02],\n",
      "       [ 1.72099557e+00],\n",
      "       [ 7.16804189e-01],\n",
      "       [ 8.51626181e-01],\n",
      "       [ 8.20632619e-01],\n",
      "       [ 8.91401251e-01],\n",
      "       [ 1.22251580e+00],\n",
      "       [ 1.99270579e+00],\n",
      "       [-5.84925384e-01],\n",
      "       [ 2.53967007e-01],\n",
      "       [ 5.44273365e-01],\n",
      "       [ 3.08722299e-01],\n",
      "       [ 6.16591674e-01],\n",
      "       [ 8.41294993e-01],\n",
      "       [ 4.93133988e-01],\n",
      "       [ 8.93984048e-01],\n",
      "       [ 7.93771533e-01],\n",
      "       [ 7.39532801e-01],\n",
      "       [ 1.17137642e+00],\n",
      "       [ 9.97812478e-01],\n",
      "       [ 1.00866022e+00],\n",
      "       [ 1.01020990e+00],\n",
      "       [ 1.21528397e+00],\n",
      "       [ 3.43331776e-01],\n",
      "       [ 5.58220467e-01],\n",
      "       [ 7.30234732e-01],\n",
      "       [ 1.84748054e-01],\n",
      "       [ 4.67306021e-01],\n",
      "       [ 9.78183222e-01],\n",
      "       [ 1.52676926e+00],\n",
      "       [ 1.35733779e+00],\n",
      "       [ 9.63719560e-01],\n",
      "       [ 1.12953511e+00],\n",
      "       [-7.09488267e-02],\n",
      "       [ 1.06444863e+00],\n",
      "       [ 1.43895417e+00],\n",
      "       [ 1.09492564e+00],\n",
      "       [-1.79625707e+00],\n",
      "       [-6.66541763e-01],\n",
      "       [ 5.83015316e-01],\n",
      "       [ 8.73838233e-01],\n",
      "       [ 2.69463788e-01],\n",
      "       [ 8.92950929e-01],\n",
      "       [-1.46883052e-01],\n",
      "       [ 9.29626643e-01],\n",
      "       [ 5.51505196e-01],\n",
      "       [ 6.38287167e-01],\n",
      "       [ 8.59891130e-01],\n",
      "       [ 9.90064088e-01],\n",
      "       [ 9.25494168e-01],\n",
      "       [ 1.22871451e+00],\n",
      "       [ 9.58037408e-01],\n",
      "       [ 9.13613303e-01],\n",
      "       [ 6.32088455e-01],\n",
      "       [ 1.09846947e-01],\n",
      "       [ 1.06806455e+00],\n",
      "       [ 1.30464873e+00],\n",
      "       [ 1.51075592e+00],\n",
      "       [ 8.33546603e-01],\n",
      "       [-8.58185283e-01],\n",
      "       [ 3.15437571e-01],\n",
      "       [ 1.50817312e+00],\n",
      "       [ 1.48751075e+00],\n",
      "       [ 1.61923338e+00],\n",
      "       [ 1.95757976e+00],\n",
      "       [ 1.35578811e+00],\n",
      "       [-7.50813015e-02],\n",
      "       [ 8.10301432e-01],\n",
      "       [ 3.90338677e-01],\n",
      "       [ 1.17034330e+00],\n",
      "       [ 1.15174717e+00],\n",
      "       [ 1.04946841e+00],\n",
      "       [ 1.07787918e+00],\n",
      "       [ 7.94804652e-01],\n",
      "       [ 6.39836845e-01],\n",
      "       [ 1.21425085e+00],\n",
      "       [ 1.46374902e+00],\n",
      "       [-1.94923072e-01],\n",
      "       [ 1.86769843e+00],\n",
      "       [ 1.62026650e+00],\n",
      "       [ 1.28811884e+00],\n",
      "       [ 1.28966851e+00],\n",
      "       [ 1.31756272e+00],\n",
      "       [ 1.54433228e+00],\n",
      "       [ 1.66933964e+00],\n",
      "       [ 1.54639851e+00],\n",
      "       [ 1.08149509e+00],\n",
      "       [ 1.11558801e+00],\n",
      "       [ 2.41569583e-01],\n",
      "       [ 1.50662344e+00],\n",
      "       [ 1.47666300e+00],\n",
      "       [ 1.63266392e+00],\n",
      "       [ 1.65177662e+00],\n",
      "       [ 1.27778765e+00],\n",
      "       [ 3.07172621e-01],\n",
      "       [ 1.19875407e+00],\n",
      "       [ 8.81586623e-01],\n",
      "       [ 7.23519461e-01],\n",
      "       [ 6.81161594e-01],\n",
      "       [ 1.52573614e+00],\n",
      "       [ 1.23284698e+00],\n",
      "       [ 1.17499234e+00],\n",
      "       [ 1.51747119e+00],\n",
      "       [ 1.46219934e+00],\n",
      "       [ 1.22664827e+00],\n",
      "       [ 4.95200226e-01],\n",
      "       [ 6.10909521e-01],\n",
      "       [ 5.30326262e-01],\n",
      "       [ 8.89851573e-01],\n",
      "       [ 1.11352177e+00],\n",
      "       [ 1.49732537e+00],\n",
      "       [ 8.97083404e-01],\n",
      "       [ 8.79520386e-01],\n",
      "       [ 1.73383748e-01],\n",
      "       [ 8.66017764e-02],\n",
      "       [ 1.06651487e+00],\n",
      "       [ 9.22394812e-01],\n",
      "       [ 1.42552362e+00],\n",
      "       [ 1.51953743e+00],\n",
      "       [ 1.54691507e+00],\n",
      "       [ 1.27313861e+00],\n",
      "       [ 7.88605939e-01],\n",
      "       [ 1.20133686e+00],\n",
      "       [ 1.17860825e+00],\n",
      "       [ 6.24340065e-01],\n",
      "       [ 1.07787918e+00],\n",
      "       [ 7.05439883e-01],\n",
      "       [-2.34253661e-02],\n",
      "       [ 1.50094129e+00],\n",
      "       [ 1.27158894e+00],\n",
      "       [ 1.59495509e+00],\n",
      "       [ 1.89507608e+00],\n",
      "       [ 1.21735020e+00],\n",
      "       [ 1.23956226e+00],\n",
      "       [ 1.12643576e+00],\n",
      "       [ 1.08097853e+00],\n",
      "       [ 1.34339069e+00],\n",
      "       [ 1.40072877e+00],\n",
      "       [ 1.58875638e+00],\n",
      "       [ 1.42397395e+00],\n",
      "       [ 1.37954984e+00],\n",
      "       [ 1.19823751e+00],\n",
      "       [ 4.95716785e-01],\n",
      "       [ 1.29586723e+00],\n",
      "       [ 1.43017266e+00],\n",
      "       [ 1.56499465e+00],\n",
      "       [ 1.43688793e+00],\n",
      "       [ 6.62048897e-01],\n",
      "       [ 9.27043846e-01],\n",
      "       [ 1.05360089e+00],\n",
      "       [ 1.22871451e+00],\n",
      "       [ 1.17757513e+00],\n",
      "       [ 1.46839805e+00],\n",
      "       [ 1.60167036e+00],\n",
      "       [ 1.36560274e+00],\n",
      "       [ 1.73597580e+00],\n",
      "       [ 2.30649758e-02],\n",
      "       [ 1.04636906e+00],\n",
      "       [ 1.29225131e+00],\n",
      "       [ 1.48286171e+00],\n",
      "       [ 1.68431986e+00],\n",
      "       [ 1.58978950e+00],\n",
      "       [ 7.99970245e-01],\n",
      "       [ 3.87755880e-01],\n",
      "       [ 1.24627753e+00],\n",
      "       [ 1.30981433e+00],\n",
      "       [ 1.64919382e+00],\n",
      "       [ 1.65745877e+00],\n",
      "       [ 1.46994773e+00],\n",
      "       [ 8.44910909e-01],\n",
      "       [ 6.74446322e-01],\n",
      "       [ 7.90155617e-01],\n",
      "       [ 1.21889988e+00],\n",
      "       [ 1.34700660e+00],\n",
      "       [ 8.77454148e-01],\n",
      "       [ 1.54949787e+00],\n",
      "       [ 7.60195175e-01],\n",
      "       [ 1.92297028e+00],\n",
      "       [ 1.56034562e+00],\n",
      "       [ 1.68535298e+00],\n",
      "       [ 1.73855859e+00],\n",
      "       [ 1.70446567e+00],\n",
      "       [ 1.81036034e+00],\n",
      "       [ 2.17453469e+00],\n",
      "       [ 1.46116622e+00],\n",
      "       [ 1.22148268e+00],\n",
      "       [-2.22817277e-01],\n",
      "       [ 1.59443853e+00],\n",
      "       [ 1.66107469e+00],\n",
      "       [ 1.89197672e+00],\n",
      "       [ 2.00975225e+00],\n",
      "       [ 1.75767129e+00],\n",
      "       [ 1.51437183e+00],\n",
      "       [ 1.56706089e+00],\n",
      "       [ 1.66778996e+00],\n",
      "       [ 1.49215978e+00],\n",
      "       [ 1.50352409e+00],\n",
      "       [ 2.09240175e+00],\n",
      "       [ 1.23181387e+00],\n",
      "       [ 1.17447578e+00],\n",
      "       [ 6.95553177e-02],\n",
      "       [ 1.58462390e+00],\n",
      "       [ 1.45858342e+00],\n",
      "       [ 1.88629457e+00],\n",
      "       [ 1.78763173e+00],\n",
      "       [-5.13640194e-01],\n",
      "       [ 5.02948616e-01],\n",
      "       [ 9.75083866e-01],\n",
      "       [ 1.64609447e+00],\n",
      "       [ 1.58359079e+00],\n",
      "       [ 1.43482169e+00],\n",
      "       [ 1.34545692e+00],\n",
      "       [ 1.10267403e+00],\n",
      "       [ 7.08022680e-01],\n",
      "       [ 1.56499465e+00],\n",
      "       [ 1.52728582e+00],\n",
      "       [ 1.55208067e+00],\n",
      "       [ 4.75054411e-01],\n",
      "       [ 1.85220165e+00],\n",
      "       [ 1.19823751e+00],\n",
      "       [ 1.31911240e+00],\n",
      "       [ 1.52986861e+00],\n",
      "       [ 1.64712759e+00],\n",
      "       [ 1.47459676e+00],\n",
      "       [ 1.51850431e+00],\n",
      "       [ 1.72926052e+00],\n",
      "       [-2.34253661e-02],\n",
      "       [-2.31539922e+00],\n",
      "       [-1.76061448e+00],\n",
      "       [ 5.48405839e-01],\n",
      "       [ 7.65360768e-01],\n",
      "       [ 6.93559018e-01],\n",
      "       [ 3.27318436e-01],\n",
      "       [ 3.11305096e-01],\n",
      "       [ 3.89822118e-01],\n",
      "       [ 6.10392962e-01],\n",
      "       [ 2.74112822e-01],\n",
      "       [ 4.18749441e-01],\n",
      "       [ 7.68460124e-01],\n",
      "       [ 1.04946841e+00],\n",
      "       [ 1.21270117e+00],\n",
      "       [ 9.11547066e-01],\n",
      "       [-2.11969530e-01],\n",
      "       [ 5.11730125e-01],\n",
      "       [ 4.85902158e-01],\n",
      "       [ 6.16591674e-01],\n",
      "       [ 5.80949079e-01],\n",
      "       [ 8.50520984e-02],\n",
      "       [ 5.13796363e-01],\n",
      "       [ 5.83531876e-01],\n",
      "       [ 3.31450911e-01],\n",
      "       [-1.07410709e+00],\n",
      "       [-3.07016452e-01],\n",
      "       [-1.15055788e+00],\n",
      "       [-1.07462365e+00],\n",
      "       [ 3.00973909e-01],\n",
      "       [-2.81705043e-01],\n",
      "       [ 3.90338677e-01],\n",
      "       [ 4.22881916e-01],\n",
      "       [ 6.01094894e-01],\n",
      "       [ 3.54696081e-01],\n",
      "       [ 7.47209113e-02],\n",
      "       [ 8.93467488e-01],\n",
      "       [ 1.08562757e+00],\n",
      "       [ 6.32605014e-01],\n",
      "       [ 4.49743003e-01],\n",
      "       [ 2.60165720e-01],\n",
      "       [ 5.56670789e-01],\n",
      "       [-6.59309932e-01],\n",
      "       [ 3.43848335e-01],\n",
      "       [ 5.14829481e-01],\n",
      "       [ 4.20815679e-01],\n",
      "       [ 5.30842821e-01],\n",
      "       [ 5.71651010e-01],\n",
      "       [ 2.80311534e-01],\n",
      "       [-3.71069812e-01],\n",
      "       [ 4.16611126e-02],\n",
      "       [ 5.43756805e-01],\n",
      "       [ 3.93954592e-01],\n",
      "       [-1.94406512e-01],\n",
      "       [-4.55268986e-01],\n",
      "       [-1.42330122e+00],\n",
      "       [-1.40367196e+00],\n",
      "       [-1.85152892e+00],\n",
      "       [-1.80348890e+00],\n",
      "       [-2.09896085e+00],\n",
      "       [-1.23475705e+00],\n",
      "       [-7.28012326e-01],\n",
      "       [-1.63405743e+00],\n",
      "       [-1.39902293e+00],\n",
      "       [-9.17073049e-01]]), 'scaler': StandardScaler()} after processing\n",
      "{'train': <torch.utils.data.dataloader.DataLoader object at 0x000002B938C6B3E0>} loaders\n",
      "Starting training...\n",
      "Epoch 1/100, Training Loss: 1.4398\n",
      "Epoch 2/100, Training Loss: 0.8725\n",
      "Epoch 3/100, Training Loss: 0.5347\n",
      "Epoch 4/100, Training Loss: 0.3337\n",
      "Epoch 5/100, Training Loss: 0.3106\n",
      "Epoch 6/100, Training Loss: 0.2436\n",
      "Epoch 7/100, Training Loss: 0.2206\n",
      "Epoch 8/100, Training Loss: 0.2014\n",
      "Epoch 9/100, Training Loss: 0.1947\n",
      "Epoch 10/100, Training Loss: 0.1819\n",
      "Epoch 11/100, Training Loss: 0.1772\n",
      "Epoch 12/100, Training Loss: 0.1676\n",
      "Epoch 13/100, Training Loss: 0.1609\n",
      "Epoch 14/100, Training Loss: 0.1575\n",
      "Epoch 15/100, Training Loss: 0.1516\n",
      "Epoch 16/100, Training Loss: 0.1466\n",
      "Epoch 17/100, Training Loss: 0.1426\n",
      "Epoch 18/100, Training Loss: 0.1391\n",
      "Epoch 19/100, Training Loss: 0.1376\n",
      "Epoch 20/100, Training Loss: 0.1319\n",
      "Epoch 21/100, Training Loss: 0.1284\n",
      "Epoch 22/100, Training Loss: 0.1258\n",
      "Epoch 23/100, Training Loss: 0.1249\n",
      "Epoch 24/100, Training Loss: 0.1218\n",
      "Epoch 25/100, Training Loss: 0.1173\n",
      "Epoch 26/100, Training Loss: 0.1192\n",
      "Epoch 27/100, Training Loss: 0.1176\n",
      "Epoch 28/100, Training Loss: 0.1105\n",
      "Epoch 29/100, Training Loss: 0.1101\n",
      "Epoch 30/100, Training Loss: 0.1071\n",
      "Epoch 31/100, Training Loss: 0.1047\n",
      "Epoch 32/100, Training Loss: 0.1023\n",
      "Epoch 33/100, Training Loss: 0.1114\n",
      "Epoch 34/100, Training Loss: 0.1040\n",
      "Epoch 35/100, Training Loss: 0.0995\n",
      "Epoch 36/100, Training Loss: 0.1003\n",
      "Epoch 37/100, Training Loss: 0.0960\n",
      "Epoch 38/100, Training Loss: 0.1004\n",
      "Epoch 39/100, Training Loss: 0.0959\n",
      "Epoch 40/100, Training Loss: 0.0963\n",
      "Epoch 41/100, Training Loss: 0.0971\n",
      "Epoch 42/100, Training Loss: 0.0953\n",
      "Epoch 43/100, Training Loss: 0.0923\n",
      "Epoch 44/100, Training Loss: 0.0896\n",
      "Epoch 45/100, Training Loss: 0.0877\n",
      "Epoch 46/100, Training Loss: 0.0872\n",
      "Epoch 47/100, Training Loss: 0.0906\n",
      "Epoch 48/100, Training Loss: 0.0976\n",
      "Epoch 49/100, Training Loss: 0.0941\n",
      "Epoch 50/100, Training Loss: 0.0946\n",
      "Epoch 51/100, Training Loss: 0.0874\n",
      "Epoch 52/100, Training Loss: 0.0861\n",
      "Epoch 53/100, Training Loss: 0.0861\n",
      "Epoch 54/100, Training Loss: 0.0867\n",
      "Epoch 55/100, Training Loss: 0.0821\n",
      "Epoch 56/100, Training Loss: 0.0877\n",
      "Epoch 57/100, Training Loss: 0.0808\n",
      "Epoch 58/100, Training Loss: 0.0855\n",
      "Epoch 59/100, Training Loss: 0.0932\n",
      "Epoch 60/100, Training Loss: 0.0883\n",
      "Epoch 61/100, Training Loss: 0.1034\n",
      "Epoch 62/100, Training Loss: 0.0887\n",
      "Epoch 63/100, Training Loss: 0.0938\n",
      "Epoch 64/100, Training Loss: 0.0901\n",
      "Epoch 65/100, Training Loss: 0.0837\n",
      "Epoch 66/100, Training Loss: 0.0855\n",
      "Epoch 67/100, Training Loss: 0.0855\n",
      "Epoch 68/100, Training Loss: 0.0863\n",
      "Epoch 69/100, Training Loss: 0.0884\n",
      "Epoch 70/100, Training Loss: 0.0827\n",
      "Epoch 71/100, Training Loss: 0.0778\n",
      "Epoch 72/100, Training Loss: 0.0805\n",
      "Epoch 73/100, Training Loss: 0.0735\n",
      "Epoch 74/100, Training Loss: 0.0746\n",
      "Epoch 75/100, Training Loss: 0.0721\n",
      "Epoch 76/100, Training Loss: 0.0686\n",
      "Epoch 77/100, Training Loss: 0.0691\n",
      "Epoch 78/100, Training Loss: 0.0676\n",
      "Epoch 79/100, Training Loss: 0.0667\n",
      "Epoch 80/100, Training Loss: 0.0661\n",
      "Epoch 81/100, Training Loss: 0.0658\n",
      "Epoch 82/100, Training Loss: 0.0657\n",
      "Epoch 83/100, Training Loss: 0.0670\n",
      "Epoch 84/100, Training Loss: 0.0643\n",
      "Epoch 85/100, Training Loss: 0.0679\n",
      "Epoch 86/100, Training Loss: 0.0662\n",
      "Epoch 87/100, Training Loss: 0.0647\n",
      "Epoch 88/100, Training Loss: 0.0646\n",
      "Epoch 89/100, Training Loss: 0.0642\n",
      "Epoch 90/100, Training Loss: 0.0637\n",
      "Epoch 91/100, Training Loss: 0.0650\n",
      "Epoch 92/100, Training Loss: 0.0660\n",
      "Epoch 93/100, Training Loss: 0.0637\n",
      "Epoch 94/100, Training Loss: 0.0656\n",
      "Epoch 95/100, Training Loss: 0.0702\n",
      "Epoch 96/100, Training Loss: 0.0719\n",
      "Epoch 97/100, Training Loss: 0.0686\n",
      "Epoch 98/100, Training Loss: 0.0690\n",
      "Epoch 99/100, Training Loss: 0.0648\n",
      "Epoch 100/100, Training Loss: 0.0642\n",
      "Starting training...\n",
      "Epoch 1/100, Training Loss: 3.4778\n",
      "Epoch 2/100, Training Loss: 1.9148\n",
      "Epoch 3/100, Training Loss: 1.2757\n",
      "Epoch 4/100, Training Loss: 1.2110\n",
      "Epoch 5/100, Training Loss: 1.1443\n",
      "Epoch 6/100, Training Loss: 1.0601\n",
      "Epoch 7/100, Training Loss: 1.0166\n",
      "Epoch 8/100, Training Loss: 0.9698\n",
      "Epoch 9/100, Training Loss: 0.9256\n",
      "Epoch 10/100, Training Loss: 0.8852\n",
      "Epoch 11/100, Training Loss: 0.8408\n",
      "Epoch 12/100, Training Loss: 0.8044\n",
      "Epoch 13/100, Training Loss: 0.7666\n",
      "Epoch 14/100, Training Loss: 0.7361\n",
      "Epoch 15/100, Training Loss: 0.7008\n",
      "Epoch 16/100, Training Loss: 0.6755\n",
      "Epoch 17/100, Training Loss: 0.6478\n",
      "Epoch 18/100, Training Loss: 0.6204\n",
      "Epoch 19/100, Training Loss: 0.5994\n",
      "Epoch 20/100, Training Loss: 0.5930\n",
      "Epoch 21/100, Training Loss: 0.5681\n",
      "Epoch 22/100, Training Loss: 0.5446\n",
      "Epoch 23/100, Training Loss: 0.5276\n",
      "Epoch 24/100, Training Loss: 0.5129\n",
      "Epoch 25/100, Training Loss: 0.4932\n",
      "Epoch 26/100, Training Loss: 0.4768\n",
      "Epoch 27/100, Training Loss: 0.4624\n",
      "Epoch 28/100, Training Loss: 0.4455\n",
      "Epoch 29/100, Training Loss: 0.4345\n",
      "Epoch 30/100, Training Loss: 0.4206\n",
      "Epoch 31/100, Training Loss: 0.4148\n",
      "Epoch 32/100, Training Loss: 0.3953\n",
      "Epoch 33/100, Training Loss: 0.3844\n",
      "Epoch 34/100, Training Loss: 0.3761\n",
      "Epoch 35/100, Training Loss: 0.3653\n",
      "Epoch 36/100, Training Loss: 0.3548\n",
      "Epoch 37/100, Training Loss: 0.3464\n",
      "Epoch 38/100, Training Loss: 0.3416\n",
      "Epoch 39/100, Training Loss: 0.3362\n",
      "Epoch 40/100, Training Loss: 0.3308\n",
      "Epoch 41/100, Training Loss: 0.3237\n",
      "Epoch 42/100, Training Loss: 0.3138\n",
      "Epoch 43/100, Training Loss: 0.3024\n",
      "Epoch 44/100, Training Loss: 0.2992\n",
      "Epoch 45/100, Training Loss: 0.2936\n",
      "Epoch 46/100, Training Loss: 0.2858\n",
      "Epoch 47/100, Training Loss: 0.2814\n",
      "Epoch 48/100, Training Loss: 0.2829\n",
      "Epoch 49/100, Training Loss: 0.2682\n",
      "Epoch 50/100, Training Loss: 0.2614\n",
      "Epoch 51/100, Training Loss: 0.2561\n",
      "Epoch 52/100, Training Loss: 0.2529\n",
      "Epoch 53/100, Training Loss: 0.2669\n",
      "Epoch 54/100, Training Loss: 0.2621\n",
      "Epoch 55/100, Training Loss: 0.2527\n",
      "Epoch 56/100, Training Loss: 0.2454\n",
      "Epoch 57/100, Training Loss: 0.2430\n",
      "Epoch 58/100, Training Loss: 0.2333\n",
      "Epoch 59/100, Training Loss: 0.2379\n",
      "Epoch 60/100, Training Loss: 0.2272\n",
      "Epoch 61/100, Training Loss: 0.2229\n",
      "Epoch 62/100, Training Loss: 0.2193\n",
      "Epoch 63/100, Training Loss: 0.2123\n",
      "Epoch 64/100, Training Loss: 0.2082\n",
      "Epoch 65/100, Training Loss: 0.2024\n",
      "Epoch 66/100, Training Loss: 0.1996\n",
      "Epoch 67/100, Training Loss: 0.1972\n",
      "Epoch 68/100, Training Loss: 0.1936\n",
      "Epoch 69/100, Training Loss: 0.1900\n",
      "Epoch 70/100, Training Loss: 0.1862\n",
      "Epoch 71/100, Training Loss: 0.1888\n",
      "Epoch 72/100, Training Loss: 0.1910\n",
      "Epoch 73/100, Training Loss: 0.1911\n",
      "Epoch 74/100, Training Loss: 0.1798\n",
      "Epoch 75/100, Training Loss: 0.1791\n",
      "Epoch 76/100, Training Loss: 0.1732\n",
      "Epoch 77/100, Training Loss: 0.1710\n",
      "Epoch 78/100, Training Loss: 0.1717\n",
      "Epoch 79/100, Training Loss: 0.1674\n",
      "Epoch 80/100, Training Loss: 0.1635\n",
      "Epoch 81/100, Training Loss: 0.1698\n",
      "Epoch 82/100, Training Loss: 0.1638\n",
      "Epoch 83/100, Training Loss: 0.1606\n",
      "Epoch 84/100, Training Loss: 0.1591\n",
      "Epoch 85/100, Training Loss: 0.1606\n",
      "Epoch 86/100, Training Loss: 0.1630\n",
      "Epoch 87/100, Training Loss: 0.1584\n",
      "Epoch 88/100, Training Loss: 0.1537\n",
      "Epoch 89/100, Training Loss: 0.1592\n",
      "Epoch 90/100, Training Loss: 0.1564\n",
      "Epoch 91/100, Training Loss: 0.1579\n",
      "Epoch 92/100, Training Loss: 0.1583\n",
      "Epoch 93/100, Training Loss: 0.1480\n",
      "Epoch 94/100, Training Loss: 0.1456\n",
      "Epoch 95/100, Training Loss: 0.1437\n",
      "Epoch 96/100, Training Loss: 0.1403\n",
      "Epoch 97/100, Training Loss: 0.1385\n",
      "Epoch 98/100, Training Loss: 0.1367\n",
      "Epoch 99/100, Training Loss: 0.1378\n",
      "Epoch 100/100, Training Loss: 0.1376\n",
      "Error in training real datasets list index out of range\n",
      "Processing higgs_boson\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mStarting real-world experiments\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m CONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreal_world\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m---> 24\u001b[0m     results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreal_world\u001b[39m\u001b[38;5;124m\"\u001b[39m][dataset] \u001b[38;5;241m=\u001b[39m \u001b[43mrun_realworld_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(results, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(CONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpaths\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull_results.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     27\u001b[0m plot_results(results, CONFIG)\n",
      "File \u001b[1;32mc:\\Users\\valer\\.vscode\\neural-interaction-detection\\src\\experiments\\run_experiments.py:215\u001b[0m, in \u001b[0;36mrun_realworld_experiment\u001b[1;34m(dataset, config)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Real-world experiment with full model suite\"\"\"\u001b[39;00m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 215\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[43mload_real_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28mprint\u001b[39m(X,y, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    217\u001b[0m     Xd, Yd \u001b[38;5;241m=\u001b[39m preprocess_data(X, y, valid_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, std_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\valer\\.vscode\\neural-interaction-detection\\src\\datasets\\realworld_datasets.py:22\u001b[0m, in \u001b[0;36mload_real_dataset\u001b[1;34m(dataset_name)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dataset_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhiggs_boson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     21\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://archive.ics.uci.edu/ml/machine-learning-databases/00280/HIGGS.csv.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 22\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgzip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     Y \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     24\u001b[0m     X \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[1;32mc:\\Users\\valer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\valer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\valer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\valer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\valer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:728\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    725\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[1;32m--> 728\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    736\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[0;32m    737\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[1;32mc:\\Users\\valer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:389\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    387\u001b[0m             \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n\u001b[0;32m    388\u001b[0m             compression \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m--> 389\u001b[0m         reader \u001b[38;5;241m=\u001b[39m BytesIO(\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m IOArgs(\n\u001b[0;32m    391\u001b[0m         filepath_or_buffer\u001b[38;5;241m=\u001b[39mreader,\n\u001b[0;32m    392\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    395\u001b[0m         mode\u001b[38;5;241m=\u001b[39mfsspec_mode,\n\u001b[0;32m    396\u001b[0m     )\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_fsspec_url(filepath_or_buffer):\n",
      "File \u001b[1;32mc:\\Users\\valer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:473\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked:\n\u001b[1;32m--> 473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[0;32m    477\u001b[0m         \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\valer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:595\u001b[0m, in \u001b[0;36mHTTPResponse._read_chunked\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    593\u001b[0m value \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 595\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m (chunk_left \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_chunk_left\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    596\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m chunk_left:\n\u001b[0;32m    597\u001b[0m             value\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_safe_read(amt))\n",
      "File \u001b[1;32mc:\\Users\\valer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:579\u001b[0m, in \u001b[0;36mHTTPResponse._get_chunk_left\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_safe_read(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# toss the CRLF at the end of the chunk\u001b[39;00m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 579\u001b[0m     chunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_next_chunk_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\valer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:539\u001b[0m, in \u001b[0;36mHTTPResponse._read_next_chunk_size\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_next_chunk_size\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;66;03m# Read the next chunk size from the file\u001b[39;00m\n\u001b[1;32m--> 539\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    541\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunk size\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\valer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\valer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1251\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1249\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1250\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\valer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1103\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from src.experiments.run_experiments import setup_environment, CONFIG, run_realworld_experiment, run_synthetic_trial, plot_results\n",
    "\n",
    "setup_environment(CONFIG)\n",
    "results = {\"synthetic\": {}, \"real_world\": {}}\n",
    "    \n",
    "# print(\"Starting synthetic experiments\")\n",
    "# for func in CONFIG[\"synthetic\"][\"functions\"]:\n",
    "#     func_results = []\n",
    "#     for trial in range(CONFIG[\"synthetic\"][\"trials\"]):\n",
    "#         try:\n",
    "#             print(f\"Running {func.__name__} trial {trial+1}/{CONFIG['synthetic']['trials']}\")\n",
    "#             result = run_synthetic_trial(func, CONFIG)\n",
    "#             func_results.append(result)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Trial failed for {func.__name__}: {str(e)}\")\n",
    "#             continue\n",
    "\n",
    "#         results[\"synthetic\"][func.__name__] = func_results\n",
    "    \n",
    "print(\"\\nStarting real-world experiments\")\n",
    "for dataset in CONFIG[\"real_world\"][\"datasets\"]:\n",
    "    results[\"real_world\"][dataset] = run_realworld_experiment(dataset, CONFIG)\n",
    "\n",
    "torch.save(results, os.path.join(CONFIG[\"paths\"][\"results\"], \"full_results.pt\"))\n",
    "plot_results(results, CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment from github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from neural_interaction_detection import get_interactions\n",
    "from multilayer_perceptron import MLP, train, get_weights\n",
    "from utils import preprocess_data, get_pairwise_auc, get_anyorder_R_precision, set_seed, print_rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate synthetic data with ground truth interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_main_effect_nets = True # toggle this to use \"main effect\" nets\n",
    "num_samples = 30000\n",
    "num_features = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synth_func(X):\n",
    "    X1, X2, X3, X4, X5, X6, X7, X8, X9, X10 = X.transpose()\n",
    "\n",
    "    interaction1 = np.exp(np.abs(X1-X2))                        \n",
    "    interaction2 = np.abs(X2*X3)  \n",
    "    interaction3 = -1*(X3**2)**np.abs(X4) \n",
    "    interaction4 = (X1*X4)**2\n",
    "    interaction5 = np.log(X4**2 + X5**2 + X7**2 + X8**2)\n",
    "    main_effects = X9 + 1/(1 + X10**2)\n",
    "\n",
    "    Y =              interaction1 + interaction2 + interaction3 + interaction4 + interaction5 + main_effects\n",
    "    ground_truth = [     {1,2},        {2,3},         {3,4},         {1,4},        {4,5,7,8}     ]\n",
    "    \n",
    "    return Y, ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "X = np.random.uniform(low=-1, high=1, size=(num_samples,num_features))\n",
    "Y, ground_truth = synth_func(X)\n",
    "data_loaders = preprocess_data(X, Y, valid_size=10000, test_size=10000, std_scale=True, get_torch_loaders=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a multilayer perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "model = MLP(num_features, [140, 100, 60, 20], use_main_effect_nets=use_main_effect_nets).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to train\n",
      "early stopping enabled\n",
      "[epoch 1, total 100] train loss: 0.1921, val loss: 0.0548\n",
      "[epoch 3, total 100] train loss: 0.0290, val loss: 0.0283\n",
      "[epoch 5, total 100] train loss: 0.0239, val loss: 0.0557\n",
      "[epoch 7, total 100] train loss: 0.0151, val loss: 0.0168\n",
      "[epoch 9, total 100] train loss: 0.0143, val loss: 0.0184\n",
      "[epoch 11, total 100] train loss: 0.0116, val loss: 0.0083\n",
      "[epoch 13, total 100] train loss: 0.0123, val loss: 0.0117\n",
      "[epoch 15, total 100] train loss: 0.0104, val loss: 0.0094\n",
      "[epoch 17, total 100] train loss: 0.0077, val loss: 0.0137\n",
      "[epoch 19, total 100] train loss: 0.0083, val loss: 0.0139\n",
      "[epoch 21, total 100] train loss: 0.0070, val loss: 0.0054\n",
      "[epoch 23, total 100] train loss: 0.0091, val loss: 0.0063\n",
      "[epoch 25, total 100] train loss: 0.0111, val loss: 0.0099\n",
      "[epoch 27, total 100] train loss: 0.0064, val loss: 0.0068\n",
      "early stopping!\n",
      "Finished Training. Test loss:  0.005764756351709366\n"
     ]
    }
   ],
   "source": [
    "model, mlp_loss = train(model, data_loaders, device=device, learning_rate=1e-2, l1_const = 5e-5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the MLP's learned weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = get_weights(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect interactions from the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise interactions              Arbitrary-order interactions\n",
      "(1, 2)        7.8430                      (1, 2)        6.8951        \n",
      "(4, 8)        3.1959                      (2, 3)        2.0953        \n",
      "(5, 8)        3.0521                      (7, 8)        1.7971        \n",
      "(7, 8)        3.0290                      (4, 5, 8)     1.6026        \n",
      "(4, 5)        2.8506                      (1, 4)        1.5912        \n",
      "(2, 3)        2.6294                      (5, 7)        1.5261        \n",
      "(1, 4)        2.5037                      (3, 4)        1.3500        \n",
      "(5, 7)        2.4460                      (4, 7)        1.0580        \n",
      "(4, 7)        2.2369                      (4, 7, 8)     0.7727        \n",
      "(3, 4)        1.8870                      (4, 5, 7, 8)  0.5467        \n"
     ]
    }
   ],
   "source": [
    "anyorder_interactions = get_interactions(model_weights, one_indexed=True)\n",
    "pairwise_interactions = get_interactions(model_weights, pairwise=True, one_indexed=True)\n",
    "\n",
    "        \n",
    "print_rankings(pairwise_interactions, anyorder_interactions, top_k=10, spacing=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise AUC 1.0 , Any-order R-Precision 1.0\n"
     ]
    }
   ],
   "source": [
    "auc = get_pairwise_auc(pairwise_interactions, ground_truth)\n",
    "r_prec = get_anyorder_R_precision(anyorder_interactions, ground_truth)\n",
    "\n",
    "print(\"Pairwise AUC\", auc, \", Any-order R-Precision\", r_prec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
